%
% ---------- header -----------------------------------------------------------
%
% project       kaneton
%
% license       kaneton
%
% file          /home/buckman/cry...n/view/book/architecture/ia32/memory.tex
%
% created       matthieu bucchianeri   [sat sep  2 11:40:35 2006]
% updated       matthieu bucchianeri   [mon oct  1 19:45:09 2007]
%

%
% memory management
%

\chapter{Memory management}

This chapter describes in details the virtual memory management
implemented in kaneton. The whole system is based on a few primitives
using heavily the paging mecanism offered by Intel's
architecture. Both address space isolation and privilege checking are
achieved using the MMU, providing a user-transparent virtual memory
management.

\newpage

%
% privilege-check capable segmentation model
%

\section{Privilege-capable segmentation model}

As explained in the section describing the bootloader and its way to
prepare the memory environment, the segmentation is not used in our
memory management model. But as Intel IA-32 architecture forces the
programmer to use segmentation while in protected mode.

The simplest way to perform null-operation segmentation is to setup
one code segment from 0 to 4 Gb and one data segment from 0 to 4
Gb. This configuration is called a flat model. One more question
remains: which privilege level should we associate with our segments?
In normal running mode, the Current Privilege Level (CPL) must be
equal to the Requested Privilege Level (RPL) value in the segment
selectors and equal to the Descriptor Privilege Level (DPL) of the
segment pointed by the segment selectors.

As we support the different privilege rings of the microprocessor
(ring 0 for the kernel, ring 1 for drivers, ring 2 for services and
ring 3 for applications), we must create 8 segments (2 per privilege
level).

The function \textit{ia32\_segmentation\_init()} creates those
segments in the GDT for later use.

%
% raw accesses to kaneton segments
%

\section{Raw accesses to kaneton segments}

Direct accesses to memory segments (in kaneton terms) is not possible
on IA-32, as it needs to bypass the MMU, which is impossible.

The \textit{segment\_read()}, \textit{segment\_write()} and
\textit{segment\_copy()} dependent code is implemented using the
region manager. We create one (two in the case of
\textit{segment\_copy()}) temporary mapping using
\textit{region\_reserve()}, then we copy the data to or from a kernel
buffer or directly from one region to another, and to finish we call
\textit{region\_release()}.

As a result, the three operations described above are very slow on
IA-32 educational implementation.

%
% creating address spaces
%

\section{Creating address spaces}

Creating an address space is not just allocating a few structures and
filling it. It also involves preparing the address space for later
operations.

The case of the kernel address space must be handled separately, as it
is more complex and critical.

%
% creating the kernel address space
%

\subsection{Creating the kernel address space}

Creating the kernel address space is a bit more complex than the
classical case.

In the core independent code, the address space is built in two steps:

\begin{itemize}
\item
  Creating the as itself (\textit{as\_reserve()});
\item
  Injecting the prereserved segments and regions (following the
  \textit{t\_init} structure's content)
\end{itemize}

On the first address space reservation, the
\textit{ia32\_kernel\_as\_init()} function is called.

This function resets all the virtual address translations and only
keep those used in the prereserved regions. Next, all the page-tables
are added as segments (otherwise they would not be referenced
anywhere).

As described later, the region machine-dependent functions rely on the
mirroring technique (see \textit{Reserving a region}). The mirroring
entry is added, pointing to the page-directory itself. The
corresponding region is injected to prevent any
\textit{region\_reserve()} on the kernel address space to return an
address in this area.

Before leaving, the function flushes all the TLB entries to ensure no
stale translation is left.

To finish, the machine dependent code of \textit{task\_init()} calls
\textit{ia32\_kernel\_as\_finalize()}, which setup the segment types
as \textit{SEGMENT\_TYPE\_SYSTEM} for the GDT segment and the
page-directory segment.

%
% creating a classical address space
%

\subsection{Creating a classical address space}

When creating a new address space, we must install a few basic
structures into this one:

\begin{enumerate}
\item
  A page-directory is built. This is done reserving a one-page segment
  and then clearing its contents.
\item
  The global memory areas must be injected and mapped: the
  \textit{.handler} section, the TSS, both GDT and IDT, and to finish,
  a ring 0 stack (see the \textbf{Task management} chapter for more
  information about these);
\item
  The page-directory base register is given to all threads, so when
  switching from one thread to another, the address space is
  automatically switched.
\end{enumerate}

The need of mapping some common regions into each address space comes
from the absense of Task State Segment, an high-level context
switching mecanism implemented on IA-32. Instead, the context
switching is done by hand. Structures like the interrupt vector and a
kernel stack are needed when doing this context switch. They must be
mapped permanently, because the address space is switched to the
kernel address space only at some advanced stages of the switching
algorithm. But these structures are mapped with the ``Supervisor''
flag enabled, so even the owner of the address space cannot access it
in normal running conditions. Please refer to the \textbf{Task
management} chapter for further information.

The third point is done getting the task associated with the new
address space and browsing its thread set. For each thread, we fill
the register CR3 (the page-directory base register) with the
page-directory base, computed with \textit{ia32\_pd\_get\_cr3()}. See
\textbf{Address space switching} section in \textbf{Task management}
chapter.

The code described above can be found in the function
\textit{ia32\_task\_as\_init()}.

%
% operations on regions
%

\section{Operations on regions}

The region manager defines three operations on regions:

\begin{itemize}
\item
  The reservation;
\item
  The releasing;
\item
  The resizing.
\end{itemize}

We must add the permission changing operation, coming from the segment
manager (see the corresponding paragraph for more information).

Other operations (splitting and coalescing) don't affect architecture
specific structure, and have no implementation issues on IA-32.

%
% reserving a region
%

\subsection{Reserving a region}

Reserving a region is the operation that create in a given address
space a mapping between one or more physical pages and the same amount
of virtual pages.

The only action performed to reserve a region is to fill the
page-tables tree, creating one or more page-tables and adding a few
entries into these.

As region is a high-level frontend, it only performs a mapping of
contiguous areas. The algorithm for contiguous mapping is quite simple:

\begin{enumerate}
\item
  We compute the \textit{pde\_start} and \textit{pde\_end}
  values. These values give the interval of page-directory entries we
  will need to loop thought. We use a macro named \textit{IA32\_PDE\_ENTRY},
  that returns for a given address the index of the page-directory
  entry that leads to the good page-table;
\item
  Identically, we compute \textit{pte\_start} and \textit{pte\_end},
  indicating the index of the first page-table entry to add into the
  first page-table, and the last page-table entry into the last
  page-table;
\item
  Now, we will need to loop throught the page-directory. So, first of
  all, we must map it into the current address space (the kernel
  address space). This is done using the \textit{ia32\_map\_chunk()}
  function. This particular function uses the \textbf{mirroring
  technique}, explained below this algorithm;
\item
  We loop throught \textit{pde\_start} and \textit{pde\_end}
  page-directory entries;
  \begin{enumerate}
  \item
    If the page-table we need to modify does not exist, we create
    it. This is done by reserving a segment and adding the
    corresponding page-directory entry;
  \item
    Next, as we mapped the page-directory, we also need to map the
    page-table into the kernel address space in order to change
    it. This is done the same way as previously;
  \item
    Now, we are able to add some page-table entries. We loop
    throught the good interval, which is determined as follow:
    \begin{itemize}
    \item
      If the current page-table is the first-one, then we start at
      \textit{pte\_start}, otherwise, we start at 0;
    \item
      If the current page-table is the last-one, then we stop our loop
      at \textit{pte\_end}, otherwise, we use the maximum value
      (1024), to fill all the page-table entries;
    \end{itemize}
    \item
      We fill these entries. Each one maps exactly one page;
    \item
      Before moving on to the next page-table, we take care of
      unmapping the previous one (\textit{ia32\_unmap\_chunk()});
  \end{enumerate}
\item
  Once the whole process is complete, we unmap the page-directory.
\end{enumerate}

The mirroring technique permits to access the current page-directory
and page-tables hierarchy in the kernel address space. To access a
page-table, this one must be mapped. And to map it, we must access
another page-table to create a mapping. As you can see, there is a
cyclic problem here.

The solution is to consider the page-directory as a page-table. One
entry in the page-directory points to the page-directory itself. This
way, accessing a page-table is done by reading or writing to a precise
address computed as follow:

$page\_table = IA32\_ENTRY\_ADDR(IA32\_PD\_MIRROR, page\_table\_index)$

The \textit{IA32\_PD\_MIRROR} constant correspond to the index of the entry
in the page-directory that points to the page-directory. To access the
page-directory itself, the formula is the following:

$page\_directory = IA32\_ENTRY\_ADDR(IA32\_PD\_MIRROR, IA32\_PD\_MIRROR)$

With this technique, we are able to modify the page-directory and the
page-tables without mapping them each time. Both
\textit{ia32\_map\_chunk()} and \textit{ia32\_unmap\_chunk()} rely on
the mirroring technique.

%
% releasing a region
%

\subsection{Releasing a region}

Releasing a region is exactly the same processing as for reserving
one, but instead of filling the page-table entries, we clear them.

\begin{enumerate}
\item
  We compute \textit{pde\_start}, \textit{pde\_end},
  \textit{pte\_start} and \textit{pte\_end} the same way;
\item
  We map the page-directory into the current address space;
\item
  We loop throught \textit{pde\_start} and \textit{pde\_end}
  page-directory entries;
  \begin{enumerate}
  \item
    We map the current page-table into the kernel address space in
    order to change it;
  \item
    Now, we are able to add some page-table entries. We loop throught
    the good interval, which is determined as follow:
    \begin{itemize}
    \item
      If the current page-table is the first-one, then we start at
      \textit{pte\_start}, otherwise, we start at 0;
    \item
      If the current page-table is the last-one, then we stop our loop
      at \textit{pte\_end}, otherwise, we use the maximum value
      (1024), to fill all the page-table entries;
    \end{itemize}
    \item
      We remove the page-table entries;
    \item
      Before moving on to the next page-table, we take care of
      unmapping the current one;
    \item
      If we unmapped all the entries present in the page-table, we
      remove it and release the associated segment;
  \end{enumerate}
\item
  Once the whole process is complete, we unmap the page-directory.
\end{enumerate}

%
% changing permissions of a region
%

\subsection{Changing permissions of a region}

On IA-32, we manage permissions with regions and not with
segments. The \textit{segment\_perms()} machine dependent code is very
similar to the two previous one.

The algorithm is quite the same, except that we modify each page-table
entry only changing the permission flags.

%
% resizing of a region
%

\subsection{Resizing of a region}

The current way of resizing a region is not optimized and rely on
other operations of the region manager for simplicity reasons.

When shrinking a region, the independent code changes the
corresponding \textit{o\_region} object size field. The work done by
the dependent code on IA-32 is to remove the invalidated page-table
entries. The current implementation inject a temporary ``virtual''
region corresponding to the memory chunk to unmap, and the directly
calls \textit{ia32\_unmap\_region()}.

When a region needs to be enlarged, the process is very similar: we
create a region directly after the region we need to enlarge. We use
\textit{ia32\_map\_region()} to fill the page-tables. Then, we
coalesce the two region into one unique.

%
% translation cache flushing
%

\subsection{Translation cache flushing}

On IA-32, flushing the whole TLB is done automatically when switching
address space (changing the value in the page-directory base
register). As all the functions modifying the virtual addresses
mapping are executed in kernel-land, we must flush some TLB entries
only when modifying mapping into the kernel address space (testing if
\textit{asid} == \textit{kasid}). The functions
\textit{ia32\_map\_chunk()} and \textit{ia32\_unmap\_chunk()} always
invalidate TLB entries since they act on the kernel address space.
When changing some mappings into a task address space, it is not
necessary to flush the TLB, as switching back to the task will
invalidate the whole caches.
