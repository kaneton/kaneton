%%
%% licence       kaneton licence
%%
%% project       kaneton
%%
%% file          /home/buckman/kaneton/view/lectures/kernels/memory-management/kernel-memory-management.tex
%%

%
% template
%

\input{../../../templates/lecture.tex}

%
% title
%

\title{Kernels - Memory management}

%
% authors
%

\author
{
  Matthieu~Bucchianeri and Renaud~Voltz\inst{1}
}

%
% figures
%

%
%\pgfdeclareimage[interpolate=true,width=188pt,height=97pt]
%                {sample}
%		{figures/sample}

% virtual memory

\pgfdeclareimage[interpolate=true,width=135pt,height=180pt]
                {vmem-overlap}
		{figures/vmem-overlap}
\pgfdeclareimage[interpolate=true,width=135pt,height=180pt]
                {vmem-contiguous}
		{figures/vmem-contiguous}
\pgfdeclareimage[interpolate=true,width=135pt,height=180pt]
                {vmem-sharing}
		{figures/vmem-sharing}

% bank

\pgfdeclareimage[interpolate=true,width=153pt,height=180pt]
                {68hc11-bank}
		{figures/68hc11-bank}

% seg

\pgfdeclareimage[interpolate=true,width=204pt,height=120pt]
                {ia32-seg}
		{figures/ia32-seg}
\pgfdeclareimage[interpolate=true,width=198pt,height=180pt]
                {ia32-multiseg}
		{figures/ia32-multiseg}
\pgfdeclareimage[interpolate=true,width=90pt,height=180pt]
                {mips-as}
		{figures/mips-as}

% paging

\pgfdeclareimage[interpolate=true,width=233pt,height=100pt]
                {paging-step1}
		{figures/paging-step1}
\pgfdeclareimage[interpolate=true,width=233pt,height=100pt]
                {paging-step2}
		{figures/paging-step2}
\pgfdeclareimage[interpolate=true,width=233pt,height=100pt]
                {paging-step3}
		{figures/paging-step3}
\pgfdeclareimage[interpolate=true,width=233pt,height=100pt]
                {paging-error-step1}
		{figures/paging-error-step1}
\pgfdeclareimage[interpolate=true,width=233pt,height=100pt]
                {paging-error-step2}
		{figures/paging-error-step2}
\pgfdeclareimage[interpolate=true,width=233pt,height=100pt]
                {paging-miss-step1}
		{figures/paging-miss-step1}
\pgfdeclareimage[interpolate=true,width=233pt,height=100pt]
                {paging-miss-step2}
		{figures/paging-miss-step2}

% tlb

\pgfdeclareimage[interpolate=true,width=187pt,height=100pt]
                {detailed-tlb}
		{figures/detailed-tlb}
\pgfdeclareimage[interpolate=true,width=270pt,height=120pt]
                {mips-tlb}
		{figures/mips-tlb}
\pgfdeclareimage[interpolate=true,width=268pt,height=100pt]
                {direct-mapped}
		{figures/direct-mapped}
\pgfdeclareimage[interpolate=true,width=196pt,height=180pt]
                {tlb-coherency-step1}
		{figures/tlb-coherency-step1}
\pgfdeclareimage[interpolate=true,width=196pt,height=180pt]
                {tlb-coherency-step2}
		{figures/tlb-coherency-step2}

% smp

\pgfdeclareimage[interpolate=true,width=210pt,height=180pt]
                {smp-coherency-step1}
		{figures/smp-coherency-step1}
\pgfdeclareimage[interpolate=true,width=210pt,height=180pt]
                {smp-coherency-step2}
		{figures/smp-coherency-step2}
\pgfdeclareimage[interpolate=true,width=210pt,height=180pt]
                {smp-coherency-step3}
		{figures/smp-coherency-step3}

% ia32-mmu

\pgfdeclareimage[interpolate=true,width=221pt,height=180pt]
                {ia32-mmu}
		{figures/ia32-mmu}
\pgfdeclareimage[interpolate=true,width=154pt,height=180pt]
                {pd-pt}
		{figures/pd-pt}

%
% document
%

\begin{document}

%
% title frame
%

\begin{frame}
  \titlepage

  \begin{center}
    \logos
  \end{center}
\end{frame}

%
% outline frame
%

\begin{frame}
  \frametitle{Outline}
  \tableofcontents
\end{frame}

% -)

\begin{frame}
  \frametitle{Map of the lessons}

  In the first lesson, we will focus on the basics of memory
  management in a kernel in order to provide the main system calls
  (\emph{mmap}).

  \begin{itemize}
  \item
    Bank switching
  \item
    Segmentation
  \item
    Paging
  \end{itemize}

  \-

  In the second lesson, we will deal with higher level algorithms of
  allocation and with swapping.

  \begin{itemize}
  \item
    User memory allocation
  \item
    Swapping
  \end{itemize}

\end{frame}

%
% physical memory & virtual memory
%

\section{Physical memory \& virtual memory}

%-)

\begin{frame}
  \frametitle{Definition of an address space and virtual memory}

  An address space is a set of memory area refering to the physical
  RAM or to I/O.

 XXX

\end{frame}

%-)

\begin{frame}
  \frametitle{Protection}

  \begin{center}
   \pgfuseimage{vmem-overlap}
  \end{center}

\end{frame}

%-)

\begin{frame}
  \frametitle{Contiguous allocation}

  \begin{center}
   \pgfuseimage{vmem-contiguous}
  \end{center}

\end{frame}

%-)

\begin{frame}
  \frametitle{Region sharing}

  \begin{center}
   \pgfuseimage{vmem-sharing}
  \end{center}

\end{frame}

%
% bank switching
%

\section{Bank switching}

%-)

\begin{frame}
  \frametitle{Bank switching or MMU of poor}

  The multiple bank technique is the simplest mecanism to implement
  virtual memory.

  \-

  The technique is also used to expand memory size with
  microcontrollers or 8-bit microprocessors with 16-bit address bus.

\end{frame}

%-)

\begin{frame}
  \frametitle{68HC11 example}

  \begin{center}
   \pgfuseimage{68hc11-bank}
  \end{center}

\end{frame}

%-)

\begin{frame}
  \frametitle{Limitations}

  \begin{itemize}
  \item
    Limited in size (for example, only 16 Kb by address space)
  \item
    More complicated programming (managing the PPAGE register),
    special compilers
  \item
    Not all possibilities we want: contiguous mapping or
    sharing\ldots{} are possible but not trivial
  \end{itemize}

  \-

  Bank switching is still used with small microprocessors, but modern
  microprocessors offer better mecanisms.

\end{frame}

%
% segmentation
%

\section{Segmentation}

% -)

\begin{frame}
  \frametitle{Overview}

  Segmentation is a mecanism where the CPU or the kernel defines
  multiple area in memory with specific privileges.

  \-

  Most MMU provides fixed segments, while more complicated one let the
  kernel filling structures to declare the segments.

\end{frame}

% -)

\begin{frame}
  \frametitle{MIPS example}

  \begin{center}
   \pgfuseimage{mips-as}
  \end{center}

\end{frame}

% -)

\begin{frame}
  \frametitle{IA-32 example, real mode}

  Real mode on Intel microprocessors divides the 1 Mb address space in
  16 segments of 64 Kb each. A segment is selected using the segment
  selector registers (the 4 upper bits).

  \-

  Even if this is called segmentation, no protection is ensured.

\end{frame}

% -)

\begin{frame}
  \frametitle{IA-32 example, protected mode}

  On IA-32 in protected mode, segments can be defined by the
  kernel. Up to 16000 segments can be simultaneously defined.

  \-

  A table, called the GDT, containts records for each segment with:

  \begin{itemize}
  \item
    Base address
  \item
    Limit
  \item
    Privilege level
  \end{itemize}

  \-

  Selecting a segment is done with segment selector registers, filled
  with the index of the required segment in the GDT.

\end{frame}

% -)

\begin{frame}
  \frametitle{IA-32 example, protected mode}

  \begin{center}
   \pgfuseimage{ia32-seg}
  \end{center}

\end{frame}

% -)

\begin{frame}
  \frametitle{IA-32 example, protected mode}

  \begin{center}
   \pgfuseimage{ia32-multiseg}
  \end{center}

\end{frame}

% -)

\begin{frame}
  \frametitle{Disabling segmentation}

  Many kernels do not use segmentation and prefer paging. But
  disabling segmentation is not possible.

  \-

  Instead, the kernel setup a flat model (or protected flat model),
  meaning that it creates one segment (per privilege level) overlaying
  all the physical memory.

  \-

  In the case of IA-32, two segments are required because permissions
  can be set either on RW or RX, so we must produce a combination RWX.

\end{frame}

%
% paging
%

\section{Paging}

% -)

\begin{frame}
  \frametitle{Overview}

  Paging is the concept of dividing the physical memory into chunk of
  constant size (for example 4 Kb) called page frames.

  \-

  These page frames can be mapped precisely into address spaces. Thus,
  a virtual address used in a program is translated by the MMU info a
  physical address.

  \-

  With this technique, protection, contiguous allocation and sharing
  can be done easily. But unlike with segmentation or bank switching,
  the MMU is more complex to build and to program, and the translation
  are slower.

  \-

  In addition, we will see later how paging makes easy to implement
  swapping technique.

\end{frame}

% -)

\begin{frame}
  \frametitle{Translation Lookaside Buffers}

  \begin{itemize}
    \item
    This translation is done using a translation cache: the
    Translation Lookaside Buffers (TLB).
    \item
    There are one or more TLB into a single MMU: for example, we
    found two TLB on UltraSPARC architectures: one for instruction
    fetches and the other for data accesses. On IA-32 and MIPS
    architecture, there is only one mixed TLB.
    \item
    These caches are often \textbf{full associative} or high degree
    \textbf{set associative}, for performances reasons. But their size
    is very small:
    \begin{tabular}{|c|c|c|}
    \hline
    Microprocessor & TLB & Entries \\
    \hline
    Pentium (non-MMX) & Instruction & 32 entries, 4-way set associative \\
    \hline
    Pentium (non-MMX) & Data & 64 entries, 4-way set associative \\
    \hline
    Pentium 4 & Instruction & 128 entries, 4-way set associative \\
    \hline
    Pentium 4 & Data & 64 entries, full associative \\
    \hline
    UltraSPARC IIi & Instruction & 64 entries, full associative \\
    \hline
    UltraSPARC IIi & Data & 64 entries, full associative \\
    \hline
    MIPS R8000 & Mixed & 384 entries, 3-way set associative \\
    \hline
    \end{tabular}
  \end{itemize}
\end{frame}

% -)

\begin{frame}
  \frametitle{TLB Organization}

    \begin{itemize}
      \item A TLB is a cache where each entry is made of two parts :

      \begin{center}
        \pgfuseimage{detailed-tlb}
      \end{center}

      \item A cache-hit occurs when:
      \begin{enumerate}
      \item
        V = 1
      \item
        ID = current ASID \textbf{or} G = 1
      \item
        VA $\leq$ requested address $<$ VA + SZ
      \end{enumerate}
    \end{itemize}
\end{frame}

% -)

\begin{frame}
  \frametitle{Scenario of page-hit}

  \begin{center}
    \pgfuseimage{paging-step1}
  \end{center}

\end{frame}

% -)

\begin{frame}
  \frametitle{Scenario of page-hit}

  \begin{center}
    \pgfuseimage{paging-step2}
  \end{center}

\end{frame}

% -)

\begin{frame}
  \frametitle{Scenario of page-hit}

  \begin{center}
    \pgfuseimage{paging-step3}
  \end{center}

\end{frame}

% -)

\begin{frame}
  \frametitle{Scenario of page-hit with error}

  \begin{center}
    \pgfuseimage{paging-error-step1}
  \end{center}

\end{frame}

% -)

\begin{frame}
  \frametitle{Scenario of page-hit with error}

  \begin{center}
    \pgfuseimage{paging-error-step2}
  \end{center}

\end{frame}

% -)

\begin{frame}
  \frametitle{Scenario of page-miss}

  \begin{center}
    \pgfuseimage{paging-miss-step1}
  \end{center}

\end{frame}

% -)

\begin{frame}
  \frametitle{Scenario of page-miss}

  \begin{center}
    \pgfuseimage{paging-miss-step2}
  \end{center}

\end{frame}

% -)

\begin{frame}
  \frametitle{What to do on a TLB-miss ?}

  When an error or TLB-miss occurs, an exception is thrown. There are
  three possible actions:

  \begin{itemize}
  \item
    Stopping the program and reporting the error to the user
    (\emph{Segmentation fault})
  \item
    Modifying the TLB entry to avoid the error (changing rights or
    ownership) and resuming the program
  \item
    Filling the missing entry and resuming the program
  \end{itemize}

  \-

  In the next slides, we will focus on the third point. This is not an
  error, remember that the TLB is a cache, meaning that it cannot host
  all the required entries.

\end{frame}

% -)

\begin{frame}
  \frametitle{Manual TLB entry replacement}

  Processors with very basic MMU let the kernel fill the TLB.

  \-

  On TLB-miss, an exception is thrown and the involved virtual address
  is passed through a register. The exception handler must look in its
  own structures an perform the TLB entry replacement by hand.

  \-

  A TLB replacement involves:

  \begin{itemize}
  \item
    Selecting an unlikely to be used entry to remove
  \item
    Building and adding the new entry
  \end{itemize}

\end{frame}

% -)

\begin{frame}
  \frametitle{Choosing a good entry to replace}

  Sometimes, the TLB cache is full, meaning that all of the few
  entries are used. Adding a new entry forces to remove an existing
  one.

  \-

  Some TLB implements a LRU (\emph{Least Recently Used}) algorithm and
  put in a register the number of the entry most unlikely to be used.

  \-

  Otherwise, the kernel can implement its own aging algorithms using
  the TLB entries facilities (accessed bit, user free
  bits\ldots). Another easier solution is to replace a random entry,
  this is fast but not really efficient.

\end{frame}

% -)

\begin{frame}
  \frametitle{MIPS example}

  \begin{center}
    \pgfuseimage{mips-tlb}
  \end{center}

  MIPS TLB entries are mapping two pages each, depending on the last
  bit of the virtual address (odd or even pages). Many page size are
  available, from 4 Kb to 256 Mb.

\end{frame}

% -)

\begin{frame}
  \frametitle{MIPS example}

  MMU registers list:

  \begin{itemize}
  \item
    ASID register: specified the current ASID value
  \item
    Index register: index of the TLB to use (for modifying or removing)
  \item
    Random register: random index of a TLB entry that can be replaced
    (the first dozen entries are protected)
  \item
    Tag register (called EntryHi): used to set the Tag word of an entry
  \item
    Entry registers (called EntryLo): used to set the Entry word of an entry
  \item
    PageMask register: used to specify the size of the page for the
    TLB entry
  \item
    Bad virtual address (BadVAddr) register: reports the address that
    caused page-miss of page-error
\end{itemize}

\end{frame}

% -)

\begin{frame}
  \frametitle{Exercise: tree-based replacement algorithm}

  Write a pseudo-algorithm for replacing TLB entries with a binary
  page tree.

  \-

  Your algorithm, given a virtual address, must fill the TLB with the
  correct entry or report an error if no translation can be done.

  \-

  Each bit of a virtual address correspond to a direction to take in
  the tree. A bit set tells to take the right child and a bit reset
  the left child.

  \-

  The leaf contains the translation. The page size is determined by
  the depth of a leaf.

\end{frame}

% -)

\begin{frame}
  \frametitle{Exercise: correction}

  \begin{enumerate}
  \item
    Pagesz $\leftarrow$ 31
  \item
    Get BadVAddr
  \item
    For each bit from left to right
    \begin{enumerate}
    \item
      Goto appropriate child
    \item
      In non-existent child, throw error
    \item
      On a leaf:
      \begin{itemize}
      \item
        Index $\leftarrow$ Random
      \item
        EntryHi $\leftarrow$ Build tag (Vaddr$_{31-pagesz}$, ASID)
      \item
        EntryLo $\leftarrow$ Build entry (Paddr, Writable)
      \item
        Pagemask $\leftarrow$ $2^{pagesz}-1$
      \end{itemize}
    \item
      Otherwise, Pagesz $\leftarrow$ Pagesz - 1
    \end{enumerate}
  \end{enumerate}

\end{frame}

% -)

\begin{frame}
  \frametitle{Semi-automatic TLB replacement}

  Some kind of MMU offers a semi-automatic TLB replacement mecanism.

  \-

  The principle of semi-automatic TLB management consist in a software
  cache in main memory. When no entry is found in the MMU's TLB, a
  preprogrammed replacement routine is called and search the software
  cache.

  \-

  If no entry is found in the software table, then an exception is
  raised to the kernel (we fallback to the previous scheme).

\end{frame}

% -)

\begin{frame}
  \frametitle{UltraSPARC example}

  On UltraSPARC, the software cache is called TSB (\emph{Translation
  Storage Buffer}) and is a direct-mapped cache of TTE
  (\emph{Translation Table Entry}). Searching the TSB involves only
  one memory access, this is quite acceptable.

  \-

  \begin{center}
    \pgfuseimage{direct-mapped}
  \end{center}

  The MMU is given only the base and the size of the TSB.

\end{frame}

% -)

\begin{frame}
  \frametitle{Full-automatic TLB replacement}

  Sophisticated MMU provides automatic TLB replacement algorithms,
  meaning that particular structures imposed by the MMU must be filled
  by the kernel.

  \-

  On TLB-miss, a preprogrammed handler is called and browse these
  structures to find a corresponding translation.

  \-

  As defining a big array for each translation should not be efficient
  (taking 4 Kb pages in a 4 Gb address space results in a 8 Mb array
  per address space), trees are often used for this purpose.

\end{frame}

% -)

\begin{frame}
  \frametitle{IA-32 example}

  \begin{center}
    \pgfuseimage{ia32-mmu}
  \end{center}

\end{frame}

% -)

\begin{frame}
  \frametitle{IA-32 example}

  \begin{center}
    \pgfuseimage{pd-pt}
  \end{center}

\end{frame}

% -)

\begin{frame}
  \frametitle{Exercise: contiguous mapping with page-directory \&
  page-tables}

  Write a procedure that create a page-directory \& page-tables
  hierarchy for a precise memory mapping (given the virtual and
  physical addresses and the size of the mapping).

  \-

  The following operation are given:

  \begin{itemize}
  \item
    \textbf{PDE\_ENTRY}: get the page-directory entry corresponding to
    a virtual address
  \item
    \textbf{PTE\_ENTRY}: get the page-table entry corresponding to
    a virtual address
  \item
    \textbf{pd\_add\_table}: add a page-directory entry pointing to a
    page table
  \item
    \textbf{pd\_get\_table}: get a page-directory entry
  \item
    \textbf{pt\_add\_page}: add a page-table entry, mapping a precise
    virtual page to a physical one
  \end{itemize}

\end{frame}

% -)

\begin{frame}
  \frametitle{Exercise: correction}

  \begin{itemize}
  \item
    pde\_start $\leftarrow$ PDE\_ENTRY(Vaddr) \\
    pde\_end $\leftarrow$ PDE\_ENTRY(Vaddr + Size) \\
    pte\_start $\leftarrow$ PTE\_ENTRY(Vaddr) \\
    pte\_end $\leftarrow$ PTE\_ENTRY(Vaddr + Size)
  \item
    i $\leftarrow$ pde\_start to pde\_end
    \begin{itemize}
    \item
      if pd\_get\_table(i) not exist then pd\_add\_table(i, new table)
    \item
      table $\leftarrow$ pd\_get\_table(i)
    \item
      j $\leftarrow$ (pte\_start if i == pde\_start, 0 otherwise) to (pte\_end if i == pde\_end, 1024 otherwise)
      \begin{itemize}
      \item
        pt\_add\_page(table, j, translation)
      \end{itemize}
    \end{itemize}
  \end{itemize}

\end{frame}

% -)

\begin{frame}
  \frametitle{Cycles in virtual memory management}

  There are a few common cycles when dealing with virtual memory.

  \begin{itemize}
  \item
    When a TLB-miss handler is called, it may generate another
    TLB-miss when accessing the kernel's structures
  \item
    When filling page-directory \& page-tables to map a region of
    memory, the page directory and/or page-tables needs to be mapped
  \end{itemize}

  \-

  Sometimes, the CPU provides facilities to avoid this cycle: a region
  in virtual memory called a bypass region exists and permits to
  bypass the MMU (this means that putting the memory management
  structures in this area will never generate TLB-miss).

  \-

  Others CPU do not. So we have to show imagination.

\end{frame}

% -)

\begin{frame}
  \frametitle{MMU bypass on MIPS and UltraSPARC}
870
  Bypassing the MMU is easy on MIPS processors: a special segment of
  memory, called \emph{kseg0} and lying from 0x80000000 to 0x9FFFFFFF
  is mapping RAM from 0x0 to 0x1FFFFFFF (about 500 Mb). No MMU
  translations are needed.

  \-

  On UltraSPARC, special instruction are needed to bypass the
  MMU. These instructions are LDA and STA (and all variant with
  different data width). A special ASI (\emph{Address Space Index}) is
  passed and indicate the LSU to bypass MMU translation.

\end{frame}

% -)

\begin{frame}
  \frametitle{Mirroring on IA-32}

  Mirroring is a trick to avoid the need of mapping the page-directory
  and the page-table when accessing them.

  \-

  The principle of mirroring is to create a page-directory entry
  pointing to the page-directory itself. By doing this:

  \begin{itemize}
  \item
    Looking at MAKE\_ADDR(mirror, mirror, offset) refers to the
    page-directory itself
  \item
    Looking at MAKE\_ADDR(mirror, index\_pt, offset) refers to a
    page-table
  \end{itemize}

  \-

  This technique (thought unofficial) is often used to solve our problem.
870
\end{frame}

% -)

\begin{frame}
  \frametitle{TLB coherency}

  The TLB is a cache, meaning that it represent a large amount of data
  placed into a smaller room.

  \-

  The algorithms described above describe how to maintain internal
  structures used by the TLB. But modifiying these structures does not
  affect the TLB directly.

  \-

  Let's imagine a page translation -- for example a page-table entry
  on IA-32 -- already in the TLB. Il you change or remove this
  page-table entry in main memory, the TLB still have the
  translation. This is a cache coherency error.

\end{frame}

% -)

\begin{frame}
  \frametitle{TLB incoherency example}

  \begin{center}
    \pgfuseimage{tlb-coherency-step1}
  \end{center}

\end{frame}

% -)

\begin{frame}
  \frametitle{TLB incoherency example}

  \begin{center}
    \pgfuseimage{tlb-coherency-step2}
  \end{center}

\end{frame}

% -)

\begin{frame}
  \frametitle{TLB invalidation or flushing}

  To avoid the previous problem, TLB entries can be invalidated to
  force their content to be reloaded from kernel's virtual mapping
  structures.

  \-

  TLB flushing involves invalidating all the TLB entries. Switching
  address space on IA-32 (loading a new value in PDBR) forces a flush
  of TLB.

  \-

  But invalidating the TLB should be avoided because next accesses to the
  TLB will be much more longer (TLB-miss, TLB replacement algorithm\ldots).

\end{frame}

% -)

\begin{frame}
  \frametitle{Coherency on multiprocessor platform}

  \begin{center}
    \pgfuseimage{smp-coherency-step1}
  \end{center}

\end{frame}

% -)

\begin{frame}
  \frametitle{Coherency on multiprocessor platform}

  \begin{center}
    \pgfuseimage{smp-coherency-step2}
  \end{center}

\end{frame}

% -)

\begin{frame}
  \frametitle{Coherency on multiprocessor platform}

  \begin{center}
    \pgfuseimage{smp-coherency-step3}
  \end{center}

\end{frame}

% -)

\begin{frame}
  \frametitle{Unmapping}

  Unmapping memory pages is very easy:

  \begin{itemize}
  \item
    Remove the translation into the kernel's or MMU's structures
  \item
    Do not forget to invalidate the corresponding entry in TLB if
    needed
  \end{itemize}

\end{frame}

% -)

\begin{frame}
  \frametitle{Using paging with segmentation}

  Segmentation is often used a bit with paging.

  \-

  On MIPS for example, there is no bit in TLB entries to tell if the
  page belong to the kernel or to the user. So this protection between
  privilege level is done by using the segmentation, putting the user
  pages below the 2 Gb and the kernel pages above.

  \-

  On IA-32, there is no way to tell if a page is code or data (this
  feature is added by AMD with the NX bit). For this reason, using a
  flat model for segmentation is not sure, since the stack can be
  executed for example. Fixing this problem can be done by forcing the
  task to be in a non executable segment.

\end{frame}

%
% allocation algorithms
%

\section{Allocation algorithms}

% -)

%\begin{frame}
%  \frametitle{Physical memory allocation}

%\end{frame}

% ... XXX user, copy on write, stack expansion, page-on-demand etc..

%
% swapping
%

\section{Swapping}

%
% bibliography
%

\section{Bibliography}

\begin{thebibliography}{4}

%  \bibitem{ID}
%    Sample
%    \newblock Sample

\end{thebibliography}

\end{document}
