%
% ---------- header -----------------------------------------------------------
%
% project       kaneton
%
% license       kaneton
%
% file          /home/mycure/kane...ecture/kernels/scheduling/scheduling.tex
%
% created       julien quintard   [fri oct 24 17:31:58 2008]
% updated       julien quintard   [wed apr 22 11:14:18 2009]
%

%
% ---------- setup ------------------------------------------------------------
%

%
% path
%

\def\path{../../..}

%
% template
%

\input{\path/template/lecture.tex}

%
% title
%

\title{Scheduling}

%
% document
%

\begin{document}

%
% title frame
%

\begin{frame}
  \titlepage
\end{frame}

%
% outline frame
%

\begin{frame}
  \frametitle{Outline}

  \tableofcontents
\end{frame}

%
% figures
%



%
% ---------- text -------------------------------------------------------------
%

%
% introduction
%

\section{Introduction}

% 1)

\begin{frame}
  \frametitle{Overview}

  This course targets \textbf{multitasking, multiprocessing or multithreading} in an operating system.

  \-

Former operating systems like MS-DOS used to run only one program at a time, then next generation of operating systems introduced \textbf{cooperative multitasking}. Finally, although software concepts were known for a long time, and the hardware allowed it, the true multitasking arrived with \textbf{preemptive} operating systems.    
 
\end{frame}

% 2)

\begin{frame}
  \frametitle{Assumptions}

 Previous lectures should be read and understood : memory and interrupts are the cornerstone of any kernel. These lectures will be intensively refered to.

\-

The bibliography contains many good papers and books, read it!

\end{frame}



%
% overview
%

\section{Overview}

\section{Threads and processes}

% 1)

\begin{frame}
  \frametitle{Threads :: Definition}

Threads are the entities scheduled for execution on the CPU. A thread is a single sequence stream within a process. Because threads have some properties of processes, they are sometimes called lightweight processes.

\-

In many respect, threads are a popular way to improve application through parallelism. The CPU switches rapidly back and forth among threads, giving illusaion that the threads are running in parallel.

\-

Each thread has its own stack. Since thread will generally call different procedures and thus a different execution history. This is why thread needs its own stack.

\-

A thread has, or consists of, a program counter (PC), a register set and a stack space. Threads of a process share together their code and data section, and operating system ressources like file descriptors and signals.

\end{frame}

% 2)

\begin{frame}
  \frametitle{Threads :: Processes versus threads}

Similarities:

\begin{itemize}
\item
Like processes, thread share CPU and only one thread is active (running) at the time.
\item
Like processes, threads within a process execute sequentially.
\item
Like processes, threads can create children.
\item
Like processes, if one thread is blocked, another thread can run.
\end{itemize}

\-

Differencies:

\begin{itemize}
\item
Unlike processes, threads are not independent one from antother.
\item
Unlike processes, all threads can access every address in the task.
\item
Unlike processes, thread are designed to assist one another. It is important to notice that processes might or might not assist one another because processes may have been created by different user. Process are to compete to get access to the CPU, not to cooperate.
\end{itemize}

\end{frame}



%
% thread implementation
%

\section{Thread implementation}

\subsection{In user-space}

%1)

\begin{frame}
  \frametitle{Presentation}

Each process owns a private \textbf{thread table} to keep track of the threads in that process. When a thread does something that may cause it to become blocked locally, for example waiting for another thread in its process to complete some work, it call a run-time system procedure. This procedure checks if that thread should be put in a blocked state, and if so starts to run another ready thread. Thread's context are stored locally, in the \textbf{thread table}.

\end{frame}

%2)

\begin{frame}
  \frametitle{Advantages}

Some architectures offer ways (understand \textit{instructions}) to store and load general-purpose registers, stack pointer and program counter. Therefore, the thread context-switch may be extremly fast with a thread implementation in user-space. Another benefit from this kind of implementation is the availability of threads on systems which do not initially support threads (no kernel support of threads).

\end{frame}

%3)

\begin{frame}
  \frametitle{Advantages}

\begin{itemize}
\item
Available on operating systems which does not offer a native support of threads (threads facilities in user-space usually come as a library linked with the threaded application). User-level threads do not require modification of the operating system.
\item
A thread must explicitely call the thread scheduler when it finished its work (with a call to \code{thread\_yield()} fo example). Therefore, thread in user-space implementation is often called \textbf{cooperative} multi-threading.
\item
Threads in user-space are lightweight, saving and restoring context are just local procedures. Much more efficient than issuing system calls to the kernel (no context save/restore, no cache flush, ...) ! Scheduling is very fast.
\item
Another advantage is that users can define thei own scheduliung algorithm for a precise task.
\end{itemize}

\end{frame}

%4)

\begin{frame}
  \frametitle{Drawbacks}

\begin{itemize}
\item
Despite their overall better performance, threads in user-space suffer from a major problem : how blocking system calls are implemented ? If a thread blocks in the kernel, how the kernel can notice the user-space scheduler to reschedule the task ? (solutions : rewrite syscalls as non-blocking (forget about it), \textbf{door upcall}, \etc{}, \textbf{wrapper}, ...).
\item
On a page-fault, the thread will block until the disk I/O for a remote page is completed ! Even though another thread could be executed during the I/O access.
\item
Roud-robin fashion scheduling is almost impossible since there is no clock interrupts inside a process.
\end{itemize}

\end{frame}

%5)

\begin{frame}
  \frametitle{Final words about user-space threads}

Despite better performance, user-space threads lack \textbf{preemption} facilities. Threads are precisely usefull in application which issue numerous possibly blocking syscalls such as servers \etc{}

\end{frame}


\subsection{In kernel space}

%6)

\begin{frame}
  \frametitle{Implementing thread in Kernel (kernel-thread)}

When a thread wants to create a new thread, or destroy an existing one, it makes a syscall to the thread manager of the kernel. It is the kernel which manage threads's context saving and restoring into kernel's structures.
\end{frame}

%7)

\begin{frame}
  \frametitle{Advantages}

\begin{itemize}
\item
All call that might block are implemented as system call, therefore if the kernel will block into a system call (semaphore \textit{P} operation for instance), it can schedule another thread to run while the blocked thread wait for the completion of his syscall. This is one aspect of \textbf{preemption}.
\item
Because the kernel knows how many threads a process own, it can give more time to an heavy process.
\item
SMP support.
\end{itemize}

\end{frame}

%8)

\begin{frame}
  \frametitle{Drawbacks}

\begin{itemize}
\item
Issuing syscalls is much more heavier than calling run-time procedures. Therefore creating, destroying threads, and any other possibly blocking syscalls are implemented at greater cost, much more overhrad will be incured.
\item
The kernel must support this thread implementation.
\end{itemize}

\end{frame}


\subsection{Hybrid implementation}

\begin{frame}
  \frametitle{Scheduler activations}

The goal of \textbf{scheduler activation} is to combine the advantages of user threads (good performance) with the advantages of kernel threads (not having to use a lot of tricks to make thing work).

\-

The kernel gives a certain number of virtual processors to processes, and the user-space runtime allocate these processors to its user-space threads. Obviously, virtual processors are replaced by real processors on multiprocessors systems.

\-

Another feature of scheduler activation is the \textbf{door upcall}, whenever a thread make a blocking syscall, the kernel has some ways to notice the user-space that this threads is now blocked. This is roughly analogous to a signal in UNIX.

\end{frame}


%
% kernel implementation
%

\section{Kernel implementation}

% 1)

\begin{frame}
  \frametitle{Kernel managers}

In order to do a kernel implementation of multi-processing (also known as multi-tasking in old documents about kernel), and one step further, of multi-threading, the kernel will be strongly overhauled. Many services and modifications have to be undertaken.

\-

Some of these modifications and additions to the core code are :

\begin{itemize}
\item
The dispatcher : the dispatcher is in charge of management of queues of runnable threads, and of thread preemption.

\item
The scheduler : the scheduler is in charge of telling what is the next thread who should get the processor. Strong theory about tasks scheduling, and hard to chose tradeoffs are part of the scheduler implementation.

\end{itemize}

\end{frame}


% 2)

\begin{frame}
\frametitle{The context-switch}

The context-switch is the process of giving the processor to another thread than the one currently running on. Although it is not obvious at a first glance, few things define a task, it is called a \textbf{context}. On most of processors, the hardware requirement to define a task would be :

\begin{itemize}
\item
a program counter
\item
a stack pointer
\item
general purpose registers
\end{itemize}

\-

And for advanced processors :

\-

\begin{itemize}
\item
a page-directory base address
\item
an interrupt stack pointer
\item
\etc{}
\end{itemize}

\end{frame}

% 3)

\begin{frame}
\frametitle{The context-switch}

Therefore, to give the processor to another task than the one currently running on, it is only required to restore the thread context : the program counter where the thread which is the last instruction that the thread executed before getting preempted, a stack pointer because each thread needs its own stack (try to figure out why), and a set of general purpose registers containing data for processing, arguments being passed to a function before a call, \etc{}

\-

Context switches on most architextures are a relatively expensive operation and as such they are avoided as much as possible. Quite a bit of actual work can be done during the time it takes to perform a context-switch.

\end{frame}

% 3)

\begin{frame}
\frametitle{Source of calls to the context-switch routine}

The context-switch routine initiates the context-switching of a thread off a processor, figures out which thread should run next, and context-switches the selected thread ont a processor for execution. It is called from many places within the operating-system.

\-

Some of situations or function calls that will induce a call to the context-switch routine on Solaris 2.6 are :

\begin{itemize}
\item
At the end of an interrupt thread
\item
After the creation of a kernel thread
\item
After a sleep or a wakeup of a thread
\item
When a thread migrate from one processor to another one
\item
When a processor state is changed to \textit{pause}
\item
During a mutex lock acquisition
\item
During a semaphore \textit{p} operation
\end{itemize}

\-

Many other operations could result in a call to the context-switch routine, for instance when the kernel offers message-passing facility, or during blocking I/O request.

\end{frame}

%4)

\begin{frame}
\frametitle{Priority-inversion}


Priority-inversion is evil.

\end{frame}

%5)

\begin{frame}
\frametitle{The solution to priority-inversion}

Solutions address situations where a thread is holding a critical ressources, such as a mutex lock, and a few extra ticks of execution time will allow the thread to complete its task and free the lock. Otherwise, if the thread is taken off the processor before releasing the ressource, other threads that need the same ressource will begin to block as long as the owner thread get rescheduled on a processor.

\end{frame}

%6)

\begin{frame}
\frametitle{The solution to priority-inversion}

\textbf{Priority inheritance} : The most common solution in microkernel architecture is the priority inheritance. When a thread get preempted whereas holding a critical ressource, if a higher priority thread needs that ressource, the owner thread will be assigned with the waiting thread priority as long as owning the critical ressource.

\-

\textbf{Quantum stretching} : Operating-systems such as Solaris offer a way to give a kernel thread some extra timeslices by stretching a thread's time quantum for a short time : this is known as \textit{preemption control}. What this does is effectively give the kthread a few extra clock ticks of execution time on a processor, beyond its time quantum, before it is switched off. This feature addresses 

\-

\textbf{Policies} : A simple solution is to establish policies : a thread should never ever wait for a ressource that a lower priority thread could acquire. In other word, differents priority threads and a ressource don't mix.

\end{frame}

\section{Processes \& threads in various kernels}

\subsection{Processes \& threads in Linux 2.6.x}

% 1)

\begin{frame}
\frametitle{Priority-inversion}

Linux, like many other operating systems, regards threads as simply processes that might share certain ressources. Instead of being something different than a thread or a group of threads, a process in Linux is simply a group threads that share something called a \textit{thread group ID (TGID)} and whatever ressource are necessary. 

\-

Some clarification must be done about Linux's treatment of processes ans threads with the terms themselves. The term \textit{task} is used in Linux to mean a thread, therefore it does not match the POSIX sense, which considers a task as a process. In the Linux task structure \code{task\_struct} (one of which exists for each thread), the TGID that is a process's POSIX PID is stored as \code{[task\_struct]->tgid}. Linux assigns a unique \textbf{PID} to each thread in \code{[task\_struct]->pid}, but the POSIX PID that most people think of is the task's TGID.

This approach makes spawning threads on Linux much faster than other operating systems like BSB or Windows.

\end{frame}

\subsection{Processes \& threads in Solaris 2.6 and after}

% 1)

\begin{frame}
\frametitle{The gap between multiprocessing and multiprocessor}

Where as most of operating systems saw threading as a way to emulate a multiple processors behavior on a single computer, Sun Microsystems directly saw threads as a process to enable parallel execution on a multiprocessor system. Over a decade, Solaris thread's implementation changed. 

\begin{itemize}
\item
System size growth (in terms of processors and memory).
\item
Multithreaded technique evolved and matured.
\item
API became standardized.
\item
Threads became ubiquitous in modern operating systems.
\item
Threaded application becam the norm, not the exception.
\end{itemize}

\end{frame}

% 2)

\begin{frame}
\frametitle{The Solaris's two-tiered model}

The very fist versions of Solaris was shipped with a MxN thread model. In this model:

\begin{itemize}
\item
Threads exist in two domains: kernel and user domain.
\item
User threads are not visible to the kernel, instead the kernel see \textbf{LightWeight Processes} (or \textit{LWPs}) which contains one or more user threads.
\item
Kernel threads (in Solaris, \textit{LWPs}) are the only schedulable entity the kernel knows.
\end{itemize}

\-

This model is often regarded as a \textbf{two-tiered model}.

\-

(schema)

\end{frame}

% 3)

\begin{frame}
\frametitle{Two-tiered advantages}

The first advantage of a two-tiered architecture is that application thread synchronization can be done either via the kernel (using system calls), or at the user level (leveraging atomic test-and-set facilities in the multiprocessor hardware)[note: see \textbf{lwarx/strx} instruction on PowerPC]. A system call may take many hundreds or even thousands of instructions, but a simple compare-and-swap operation takes just one (although this may involve a considerable number of clock cycles to complete).

\-

The other advantage of a two-tiered implementation is that the cost of context switching in a user-level scheduler is considerably less expensive than with the kernel's scheduler. In the early days, it was expected that user-level scheduling would be orders of magnitude faster than kernel scheduling.

\-

The first advantage has proven to be significant, but the second advantage has not. Building a user-level scheduler that works well in tandem with the kernel's scheduler is a significant challenge. However, the kernel's ability to efficiently schedule many threads has improved.

\end{frame}

% 4)

\begin{frame}
\frametitle{Recent innovations}

Solaris 2.5 was a watersched in Solaris thread's implementation. Solaris 2.5.1 provided support for \textit{UltraSPARC} multiprocessor, and therefore saw big changes.

\end{frame}

% 5)

\begin{frame}
\frametitle{Preemption control}

Solaris 2.6 software (August, 1997) addressed a number of issues relating to the visibility of userlevel threads to the kernel. One issue was that the kernel had no knowledge of user-level thread synchronization. An application thread can acquire a mutex using a simple, atomic test-and-set instruction, without troubling the kernel. In well-designed, scalable threaded applications, mutexes are held only for very short durations. It is not a good idea to preempt a thread that  is holding mutex, since other threads may end up having to wait for the mutex holder to run again.

\-

Solaris 2.6 software introduced the concept of the 'don't preempt me' flag. When acquiring a lock (or any other critical operation), the user thread set the flag in a shared structure of the corresponding LWP. When rescheduling, the kernel see the flag and decide to postpone the thread preemption for a short period of time.

\-

Obviously some mechanisms are set to avoid any abuses of this preivilege by the application.

\end{frame}

% 6)

\begin{frame}
\frametitle{Scheduler Activation}

Prior to Solaris 2.6 software, the kernel used a special signal, SIGWAITING, to inform the threads library that all LWPs were blocked in the kernel. This gave the library the opportunity to create another LWP so it could to continue to run other, nonblocking threads. In Solaris 2.6 software, this mechanism was augmented by the preferential use of a \textbf{door upcall}. Essentially, this involves the kernel being able to call into the user-level thread scheduler to adjust the number of LWPs in the process pool of LWPs. This door mechanism is more efficient than a signal, but if necessary, Solaris 2.6 software falls back to using the SIGWAITING mechanism.

\end{frame}

% 7)

\begin{frame}
\frametitle{Breaking the 32-Bit Barrier}

Of course, the most significant innovation in Solaris 7 software was the introduction of 64-bit address spaces. Until then, 32-bit addressing limited each process to just four gigabytes (GB) of virtual memory. For threaded applications the issue was more acute, since thread stacks had to share the four-gigabyte process address space with program text and data.

\-

By default, each thread stack has an adjacent \textit{red zone}, an unmapped region of at least one page that will trap stack overflows. Although red zones do not consume physical memory, they do reduce the amount of address space available for other purposes. Each kernel thread also has a stack and a red zone. The kernel thread stack size is configurable. In 32-bit kernels on UltraSPARC systems, it defaults to eight kilobytes (KB).  All kernel thread stacks are allocated in the \textit{kernel pageable segment} known as \textit{segkp}, but this is fixed at 512 MB for all 32-bit kernels and the 64-bit kernel of Solaris 7 software.

\end{frame}

% 7bis)

\begin{frame}
\frametitle{Breaking the 32-Bit Barrier}

So, with 16-KB stacks (each with an eight-KB red zone) there is a limit of approximately 21,000 stacks (a maximum of 21,000 LWPs system-wide), consuming about 340 MB of physical memory. From Solaris 8 software onwards, the 64-bit kernel allows segkp to be sized from 512 MB to 24 GB, with the default being two gigabtye (sufficient for more than 87,000 kernel thread stacks/LWPs).

\end{frame}

% 8)

\begin{frame}
\frametitle{What's wrong with the MxN implementation}

For some reasons, the MxN implementation has been retired since Solaris 2.8. We will discuss the two main reasons which lead to this removal.

\end{frame}

% 9)

\begin{frame}
\frametitle{Threads and Signals Don't Mix}

The implementation of synchronous signals in a multithreaded environment is not difficult. The signal can simply be delivered straight to the LWP on which the thread that triggered the signal is running. However, asynchronous signals are a different matter in an MxN implementation, since the only application thread that has the signal unmasked may not be currently running on an LWP.

\-

The old MxN implementation attempted to solve the asynchronous signal issue by introducing a dedicated LWP, Asynchronous Signal LWP (ASLWP), into the process model. Whenever the kernel wants to deliver an asynchronous signal to a process and ASLWP is present, the kernel will notify ASLWP instead of attempting to deliver the signal directly to an LWP. Once ASLWP sees a suitable application thread running on an LWP, it asks the kernel to redirect the pending signal to that LWP. Not only is this very complex to implement correctly, but it also means that ASLWP can become a bottleneck where there is a high volume of signals.

\end{frame}

% 10)

\begin{frame}
\frametitle{Bringing fresh stuffs with Solaris 9}

Solaris 9 brought new concepts about thread's implementation. Thereafter shows some of the most noticeable innovations \etc{}

\end{frame}

% 11)

\begin{frame}
\frametitle{Bringing fresh stuffs with Solaris 9}

\textbf{MxN Implementation Retired} : The old MxN implementation has been gracefully retired and replaced with an enhanced version of the 1:1 implementation.

\-

\textbf{Adaptive Mutexes Revisited} : A thread waiting for a process private mutex will spin only if the lock holder is currently running on a CPU. The process shared case remains unchanged. If there is more than one CPU, the thread will always spin before blocking. If there is only one processor on the system, there is no need to spin because there is a little chance that anything release the lock (aside from \textit{SEU}), therefore the thread shall be immediately preempted.

\-

\textbf{Adaptive Mutex Unlock} : When a thread is about to release the mutex it is holding, it looks to see if there are any waiters spinning. If so, it releases the lock and spins itself for a short while to see if the lock is acquired by another thread. This boosts performance because the thread releasing the lock no longer needs to enter the kernel to wake up a waiter.

\end{frame}

\subsection{Processes \& threads in QNX}

% 1)

\begin{frame}
\frametitle{Thread data structure}

QNX supports POSIX threads model. Like many kernels, a thread is defined by a private structure (each thread own one) which contains:

\-

\begin{itemize}
\item
\textit{tid} : identifying a thread by a unique \textit{thread ID}
\item
name : each thread can have a name
\item
register set : the thread \textbf{context}
\item
stack : stored within the address space of its process
\item
signal mask : each thread has its own signal mask
\item
cancellation handlers : callback function that are executed when the thread terminates
\end{itemize}

\end{frame}

% 2)

\begin{frame}
\frametitle{Thred Local Storage}

Beside these features, QNX adds a more singular feature to its thread implementation. Remember that each process is MMU-protected from each other, and each process may contain one or more threads that share the process's address space. The main difference between QNX threads and much of other operating systems threads implementation is that threads still have some \textbf{private} data are called \textit{thread local storage} or \textit{TLS}. The TLS is used to store \textbf{per-thread} information, and provides a mechanism for associating a process global integer key with a unique per-thread data-value.

\end{frame}

% 3)

\begin{frame}
\frametitle{Thread life cycle}

QNX offers significantly more thread's state than any other common kernels. QNX's thread may be in one of the following states : (schema).

\end{frame}



\section{Kernel tuning}

% 1)

\begin{frame}
\frametitle{Everything as a thread}

In microkernel, very few code make part of the essential monolitic code of the kernel, everything in a microkernel must be considered as a thread.

\-

Therefore, most of kernel services are regarded as a thread : for example the code for waiting for a thread is ported to a \textbf{kernel-thread}. Kernel-thread are like user-defined threads, excepts there are created directly by the kernel. Finally very few code remains monolitic.

\-

The drawback of this implementation is greater cost of calling the system. Refer to the \name{mach} kernel for performance benchmarks.

\end{frame}

% 2)

\begin{frame}
\frametitle{Secure the interrupt handlers}

One most of systems (including Solaris), interrupts handler are ported threads. It brings two big advantages :

\begin{itemize}
\item
Security: interrupts handlers no more run with superuser privilege.
\item
Priority: even though the low-level handler can preempt the system, the code for the user-defined interrupt handler can be assigned a priority and run as a thread. Therefore an implicit priority can be assigned to any interrupt-handlers, just with assigning a certain priority to the interrupt handler thread.
\end{itemize}

\end{frame}



%
% multicore
%

\section{Multicore}

% 1)

\begin{frame}
\frametitle{Asymetrical MultiProcessor}

Each processor gets :
\begin{itemize}
\item
One space memory
\item
One image of the kernel loaded into his private memory
\end{itemize}

\-

Communication between cores must be explicit, with the use of a communication protocol. Processors must exchange gloabl data such as global variables, and global events such as process preemption, ressource freeing, ...

\-

The good thing about AMP is it require a little modification of the kernel core.

\end{frame}

% 2)

\begin{frame}
\frametitle{Drawbacks of AMP}

In this context, migrating task from one core to another became extremly painful : a complex protocol has to be setup to migrate the task context frome one kernel to another.

\-

Moreover, because each processor needs one kernel image, the memory is quickly wasted with additional processor. Because of bus contention, it is almost impossible to have more than two processors in this architecture.

\end{frame}

% 3)

\begin{frame}
\frametitle{Symetrical MultiProcessing}

Each processor sees the same memory, there is only one kernel image in memory. This image is the same for every processors. Nonetheless, each processors cannot be in the same kernel service (or running the same threads) at the same time.

\-

Communication between cores became implicit. Every processors shares the same memory, therefore access to global variables are seen locals. No need to use some heavy message passing protocol, but take care of concurrent access !

\-

Easy task migration (and possibly load balancing) : tasks are dispatched on the first available processor.

\-

Working with more than two processor is transparent, and an SMP system will work even if only one processor is available, which may make think of reduncy.

\end{frame}

% 4)

\begin{frame}
\frametitle{Kernel modification}

Some complex modifications of code have to be undertaken :

\begin{itemize}
\item
Cache coherency
\item
Scheduling and cache contention
\item
I/O routing
\item
Task affinity
\item
Atomic access
\end{itemize}

\end{frame}

% 5) 

\begin{frame}
\frametitle{Enforcing atomic access}

Atomic access can be achieved with many different means:

\-

The first mean is to assert an exclusive access on the data bus : for example with the LOCK instruction on Intel. This instruction prevent any other processor to access the memory during a lap of time.

\-

Another mean is to use atomic instructions provided by the architecture (like \textit{lwarx/strcx} on PowerPC).

\end{frame}

% 6)

\begin{frame}
\frametitle{Asserting cache coherency}

\textbf{Race condition} happens when two or more processors have a diffrent image of the main portion of memory, stored into their L1 cache.

\-

To assert the cache coherency, functions should be protected with spinlock or reentrant. Modern architectures like Intel offer an hardware solution : the snooper. The snooper spy data bus accesses made by processors and is in charge of assuring the cache coherency.

\end{frame}

% 7)

\begin{frame}
\frametitle{InterProcessor Interrupt}

Some actions of one processors must be notified to other processors immediately.

\begin{itemize}
\item
Task suspension
\item
Task wakeup
\item
Semaphore \textit{verhog}
\item
Message send
\item
\etc{}
\end{itemize}

\end{frame}


%
% conclusion
%

\section{Conclusion}

% 1)

\begin{frame}
  \frametitle{Conclusion}

  In this course, basic concepts of multitasking and associated scheduling algorithms has been shown.

 

\end{frame}



%
% bibliography
%

\section{Bibliography}

\begin{thebibliography}{3}
  \bibitem{Hp-UX}
HP-UX Linker and Libraries User's Guide, HP 9000 Computers, HP

  \bibitem{Sun}
Linkers and Libraries Guide, Sun Microsystems

\end{thebibliography}


\end{document}
